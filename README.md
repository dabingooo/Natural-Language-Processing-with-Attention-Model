# Attention Models for Natural Language Processing

Attention models are used for various applications like Machine Translations, Text Summarizations, Auto Complete, Question Answering, Chat Bots and many more. Unlike Recurrent Neural Networks, it works very well with very long sequences. So, one of the widely used attention model is **Transformers**.

Some of the State-of-the-art models are: **GPT-2**(3 is latest one) by OpenAI, **BERT**(Bidirectional Encoder Representations from Transformers), **T5**(Text-to-Text Transfer Transformer).

